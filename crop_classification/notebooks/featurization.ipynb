{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97afbedd",
   "metadata": {},
   "source": [
    "# Crop Type Classification - Featurization\n",
    "\n",
    "This notebook performs featurization on the cleaned NDVI timeseries data to prepare it for model training.\n",
    "\n",
    "### Conda environment setup\n",
    "Before running this notebook, let's build a conda environment. If you do not have conda installed, please follow the instructions from [Conda User Guide](https://docs.conda.io/projects/conda/en/latest/user-guide/index.html). \n",
    "\n",
    "```\n",
    "$ conda create --name 'env_name' --file requirements.txt\n",
    "$ conda activate 'env_name'\n",
    "```\n",
    "\n",
    "### Key Libraries:\n",
    "\n",
    "- [Geopandas](https://geopandas.org/en/stable/docs.html), [Pandas]((https://xgboost.readthedocs.io/en/stable/)): Data handling and manipulation.\n",
    "- [Sklearn](https://scikit-learn.org/0.21/documentation.html): Train/test split, preprocessors and encoders\n",
    "\n",
    "\n",
    "The key steps are:\n",
    "\n",
    "- Train/Test Split: Split the featurized data into training and test sets for model fitting and evaluation.\n",
    "- Feature Selection: Select only the NDVI features needed for crop classification. Remove unnecessary meta data columns.\n",
    "- Label Encoding: Label encode the crop type classes into numeric labels.\n",
    "- Scaling: Scale the NDVI features to have zero mean and unit variance to improve model convergence.\n",
    "\n",
    "The output of this notebook are preprocessed pandas DataFrames with selected features, encoded targets and scaled NDVI data ready for model training,validation and testing.\n",
    "\n",
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964bc8a4",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3af7f06-cb6d-4c23-a3b7-d9a5289e4493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "    if kernel_is_loaded:\n",
    "        pass\n",
    "except:\n",
    "    os.chdir('/'.join(os.getcwd().split('/')[:-1]))\n",
    "    kernel_is_loaded = True\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import display\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.options.display.max_columns = 20\n",
    "\n",
    "# Seeding\n",
    "def seed_everything(seed = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59b8fbdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oct_1f</th>\n",
       "      <th>oct_2f</th>\n",
       "      <th>nov_1f</th>\n",
       "      <th>nov_2f</th>\n",
       "      <th>dec_1f</th>\n",
       "      <th>dec_2f</th>\n",
       "      <th>jan_1f</th>\n",
       "      <th>jan_2f</th>\n",
       "      <th>feb_1f</th>\n",
       "      <th>feb_2f</th>\n",
       "      <th>mar_1f</th>\n",
       "      <th>mar_2f</th>\n",
       "      <th>apr_1f</th>\n",
       "      <th>apr_2f</th>\n",
       "      <th>crop_name</th>\n",
       "      <th>sowing_period</th>\n",
       "      <th>harvest_period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>189.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>Wheat</td>\n",
       "      <td>nov_2f</td>\n",
       "      <td>mar_1f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>171.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>Wheat</td>\n",
       "      <td>nov_2f</td>\n",
       "      <td>mar_1f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>166.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>Wheat</td>\n",
       "      <td>nov_2f</td>\n",
       "      <td>feb_2f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   oct_1f  oct_2f  nov_1f  nov_2f  dec_1f  dec_2f  jan_1f  jan_2f  feb_1f  \\\n",
       "0   189.0   191.0   173.0   126.0   132.0   171.0   183.0   187.0   184.0   \n",
       "1   171.0   166.0   142.0   132.0   165.0   185.0   190.0   188.0   180.0   \n",
       "2   166.0   147.0   129.0   131.0   159.0   188.0   197.0   192.0   185.0   \n",
       "\n",
       "   feb_2f  mar_1f  mar_2f  apr_1f  apr_2f crop_name sowing_period  \\\n",
       "0   180.0   166.0   130.0   120.0   124.0     Wheat        nov_2f   \n",
       "1   171.0   143.0   130.0   123.0   121.0     Wheat        nov_2f   \n",
       "2   172.0   121.0   121.0   116.0   118.0     Wheat        nov_2f   \n",
       "\n",
       "  harvest_period  \n",
       "0         mar_1f  \n",
       "1         mar_1f  \n",
       "2         feb_2f  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data_files/preprocessed_data.csv')\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cd8750",
   "metadata": {},
   "source": [
    "# Train, Test and Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22b5a008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Samples with less than 3 occurrences cannot be divided into three parts (Train, Validation, Test). \n",
    "# These are excluded before splitting and then reintroduced to the training set to enhance generalization.\n",
    "\n",
    "data['crop_sp_hp'] = data['crop_name']+'_'+data['sowing_period']+'_'+data['harvest_period']\n",
    "\n",
    "comb_under_three = data.crop_sp_hp.value_counts()[data.crop_sp_hp.value_counts() < 3].index\n",
    "\n",
    "samples_under_three = data[data['crop_sp_hp'].isin(comb_under_three)]\n",
    "\n",
    "data.drop(samples_under_three.index, inplace=True)\n",
    "\n",
    "samples_under_three.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f71a1b5-24c5-47a2-a1a6-3775d58a9cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16101, 18)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(5368, 18)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(5367, 18)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Wheat      0.814111\n",
       "Potato     0.114341\n",
       "Mustard    0.071548\n",
       "Name: crop_name, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Wheat      0.813711\n",
       "Potato     0.114382\n",
       "Mustard    0.071908\n",
       "Name: crop_name, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Wheat      0.813490\n",
       "Potato     0.114589\n",
       "Mustard    0.071921\n",
       "Name: crop_name, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Wheat      13108\n",
       "Potato      1841\n",
       "Mustard     1152\n",
       "Name: crop_name, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Wheat      4368\n",
       "Potato      614\n",
       "Mustard     386\n",
       "Name: crop_name, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Wheat      4366\n",
       "Potato      615\n",
       "Mustard     386\n",
       "Name: crop_name, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train-Validation-Test split: 60-20-20 by keeping the data distribution constant across all 3 data sets.\n",
    "# Stratification is perfomed based on crop_name, sowing_period and harvest_period. \n",
    "\n",
    "train_test, val = train_test_split(data, test_size=0.2, \n",
    "                                   stratify=data[['crop_name', 'sowing_period', 'harvest_period']], random_state=0)\n",
    "\n",
    "train, test = train_test_split(train_test, test_size=0.25, \n",
    "                                   stratify=train_test[['crop_name', 'sowing_period', 'harvest_period']], random_state=0)\n",
    "\n",
    "display(train.shape, val.shape, test.shape, \n",
    "        train.crop_name.value_counts(normalize=True), val.crop_name.value_counts(normalize=True), test.crop_name.value_counts(normalize=True),\n",
    "        train.crop_name.value_counts(normalize=False), val.crop_name.value_counts(normalize=False), test.crop_name.value_counts(normalize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d95eacc-973a-4416-9293-8c6292c4eda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding samples with less than 3 occurrences back to the training set to aid generalization. \n",
    "\n",
    "train = pd.concat([train, samples_under_three], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16b5a5f",
   "metadata": {},
   "source": [
    "# Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f21b662a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding crop classes. \n",
    "\n",
    "crop_label = {'Mustard':0, 'Wheat':1, 'Potato':2}\n",
    "\n",
    "for df in train, val, test:\n",
    "    df['crop_name'] = df['crop_name'].apply(lambda crop:crop_label[crop])\n",
    "    df.drop(['sowing_period', 'harvest_period', 'crop_sp_hp'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631cc571",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b562ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the train set to the standard scaler and transforming the test and validation sets\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train.loc[:,'oct_1f':'apr_2f'] = scaler.fit_transform(train.drop('crop_name', axis=1))\n",
    "val.loc[:,'oct_1f':'apr_2f'] = scaler.transform(val.drop('crop_name', axis=1))\n",
    "test.loc[:,'oct_1f':'apr_2f'] = scaler.transform(test.drop('crop_name', axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82765a5",
   "metadata": {},
   "source": [
    "# File Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8a68616",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('data_files/train.csv', index=False)\n",
    "val.to_csv('data_files/val.csv', index=False)\n",
    "test.to_csv('data_files/test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
